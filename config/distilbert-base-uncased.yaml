model:
  name: distilbert-base-uncased
comment: null
result_dir: results/distilbert-base-uncased

debug: false
seed: 20210425

train:
  max_epochs: 100
  SAM: false
  folds: 
    - 1
    - 2
    # - 3
    # - 4
    # - 5
  checkpoints: 
    - null
    - null
    # - null
    # - null
    # - null
  loss: 
    name: focal # ce, focal
    gamma: 2
  
  finetune:
    do: true
    step1_epochs: 2
    step2_epochs: 4
    
  lr: 0.0001
  scheduler:
    name: ReduceLROnPlateau
    params:
      factor: 0.5
      patience: 3
      verbose: true
  
dataset:
  dir: data/ori
  batch_size: 40
  num_workers: 8
