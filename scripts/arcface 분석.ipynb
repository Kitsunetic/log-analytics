{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data3/SIG/log-analytics\n"
     ]
    }
   ],
   "source": [
    "%load_ext lab_black\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import multiprocessing\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from pprint import pformat\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_optimizer\n",
    "import yaml\n",
    "from easydict import EasyDict\n",
    "from pytorch_transformers import (\n",
    "    BertForSequenceClassification,\n",
    "    BertTokenizer,\n",
    "    DistilBertForSequenceClassification,\n",
    "    DistilBertTokenizer,\n",
    "    RobertaForSequenceClassification,\n",
    "    RobertaTokenizer,\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.optim import Adam, AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AlbertForSequenceClassification,\n",
    "    AlbertTokenizer,\n",
    "    DebertaForSequenceClassification,\n",
    "    DebertaTokenizer,\n",
    "    SqueezeBertTokenizer,\n",
    "    SqueezeBertForSequenceClassification,\n",
    "    XLNetTokenizer,\n",
    "    XLNetForSequenceClassification,\n",
    ")\n",
    "\n",
    "from datasets import load_test_data, load_train_data, load_train_total_data\n",
    "from utils import SAM, AverageMeter, CustomLogger, FocalLoss, seed_everything\n",
    "from copy import deepcopy\n",
    "\n",
    "from main import MyTrainer\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "postfix = \"distilbert-base-uncased-arcface-AdamW-lr5e-05-dsver5_1\"\n",
    "fold = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config/distilbert-base-uncased-ver5-arcface_focal.yaml\", \"r\") as f:\n",
    "    C = EasyDict(yaml.load(f, yaml.FullLoader))\n",
    "    C.result_dir = Path(C.result_dir)\n",
    "    C.dataset.dir = Path(C.dataset.dir)\n",
    "    C.log = CustomLogger()\n",
    "    seed_everything(C.seed, deterministic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': {'name': 'distilbert-base-uncased'},\n",
       " 'comment': None,\n",
       " 'result_dir': PosixPath('results/distilbert-base-uncased'),\n",
       " 'debug': False,\n",
       " 'seed': 20210425,\n",
       " 'train': {'SAM': False,\n",
       "  'folds': [1],\n",
       "  'checkpoints': [None],\n",
       "  'loss': {'name': 'arcface',\n",
       "   'params': {'gamma': 2.0, 's': 45.0, 'm': 0.1, 'crit': 'focal'}},\n",
       "  'optimizer': {'name': 'AdamW'},\n",
       "  'finetune': {'do': True, 'step1_epochs': 3, 'step2_epochs': 5},\n",
       "  'max_epochs': 12,\n",
       "  'lr': 5e-05,\n",
       "  'scheduler': {'name': 'ReduceLROnPlateau',\n",
       "   'params': {'factor': 0.5, 'patience': 3, 'verbose': True}}},\n",
       " 'dataset': {'dir': PosixPath('data/ori'),\n",
       "  'ver': 5,\n",
       "  'batch_size': 35,\n",
       "  'num_workers': 8,\n",
       "  'oversampling': True,\n",
       "  'oversampling_scale': 20},\n",
       " 'log': <utils.CustomLogger at 0x7fa7f7529b00>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained results/distilbert-base-uncased/distilbert-base-uncased-arcface-AdamW-lr5e-05-dsver5_1.pth\n",
      "\u001b[34m[2021-05-09 21:46:40  INFO] Oversampling with scale 20\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "trainer = MyTrainer(C, fold, f\"results/distilbert-base-uncased/{postfix}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fa7f75255f8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = trainer.model\n",
    "model.eval()\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = []\n",
    "\n",
    "\n",
    "def hook(model, input, output):\n",
    "    activation.append(output.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7fa7f7560438>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pre_classifier.register_forward_hook(hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdl, vdl = load_train_data(\n",
    "    C.dataset.dir, C.seed, fold, trainer.tokenizer, 50, C.dataset.num_workers, C.dataset.ver, train_shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = pd.read_csv(\"data/ori/train.csv\")\n",
    "sdf = pd.read_csv(\"data/ori/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "deck1 = np.load(\"results/distilbert-base-uncased/distilbert-base-uncased-arcface-AdamW-lr5e-05-dsver5_1-deck1.npz\")\n",
    "ttlevels = torch.tensor(deck1[\"tlevel\"])\n",
    "tfeats = torch.tensor(deck1[\"feat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "deck2 = np.load(\"results/distilbert-base-uncased/distilbert-base-uncased-arcface-AdamW-lr5e-05-dsver5_1-deck2.npz\")\n",
    "sfeats = torch.tensor(deck2[\"feat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([472972, 768]), torch.Size([1418916, 768]), torch.Size([472972]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfeats.shape, sfeats.shape, ttlevels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfeats_ = tfeats.cuda()\n",
    "sfeats_ = sfeats.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfeats_star_ = tfeats_.pow(2).sum(dim=1).sqrt_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfeat_ = sfeats_[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfeat_star_ = sfeat_[None].pow(2).sum(dim=1).sqrt_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_ = (tfeats_ * sfeat_[None]).sum(dim=1) / (tfeats_star_ * sfeat_star_).clamp(min=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000], device='cuda:0')\n",
      "tensor([358099, 355501, 358837, 362058, 275334, 274706, 275514, 277581, 250713,\n",
      "        243387, 240368, 241179, 254472, 251328, 254883, 273504, 328239, 327014,\n",
      "        313114, 316042, 309000, 291531, 311460, 312634, 339330, 338482, 336358,\n",
      "        337122, 348892, 340709, 349017, 353003, 290236, 288463, 279891, 285583,\n",
      "        171551, 169507, 171926, 172977, 139514, 132771, 127555, 128125, 141462,\n",
      "        140842, 145106, 159562, 217312, 214697, 205749, 214455, 194598, 193795,\n",
      "        197961, 198991, 221116, 219570, 217477, 217697, 226714, 224181, 231136,\n",
      "        236173, 123698, 117576, 109468, 112568, 101393, 100427, 107830, 109448,\n",
      "         77519,  76459,  62532,  64339,  81713,  79746,  87422,  89195,  28228,\n",
      "         22567,  14751,  16525,  10245,   2570,  11645,  14115,  39387,  37642,\n",
      "         30845,  30951,  48569,  40682,  52849,  54323, 193405, 187846, 173030,\n",
      "        174518], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "values_, indices_ = dist_.topk(100, dim=0, largest=True)\n",
    "print(values_[-100:])\n",
    "print(indices_[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttlevels[355501]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jan 27 20:28:22 localhost sshd[6222]: Failed password for invalid user www from 35.184.222.44 port 49768 ssh2'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf.full_log[355501]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jan 22 14:13:43 localhost systemd: Unit esild-ml.service entered failed state.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.full_log[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('shim': conda)",
   "language": "python",
   "name": "python361064bitshimconda5dcd412cc48446db92fbc68fce2a3d60"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
